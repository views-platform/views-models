{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from views_pipeline_core.managers.model import ModelManager, ModelPathManager\n",
    "from views_pipeline_core.managers.ensemble import  EnsembleManager, EnsemblePathManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sonja/Desktop/views-platform/views-models/models')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = os.getcwd()\n",
    "target_dir = Path(base_dir+\"/models/\")\n",
    "target_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_manager = ModelManager(model_path=ModelPathManager(configs_dir))\n",
    "model_manager = ModelManager(model_path=ModelPathManager('/home/sonja/Desktop/views-platform/views-models/models/blank_space'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update repository structure:\n",
    "def generate_repo_structure(folders, scripts, model_name, root_key=\"model_dir\"):\n",
    "    \"\"\"Generate a structured repository tree with correct folder hierarchy and script placement.\"\"\"\n",
    "\n",
    "    if root_key not in folders:\n",
    "        raise ValueError(f\"Root key '{root_key}' not found in folders dictionary\")\n",
    "\n",
    "    root_path = Path(folders[root_key])  # Get the main model directory path\n",
    "    tree = [model_name]  # Start with the model name\n",
    "    folder_structure = {}\n",
    "\n",
    "    # Build folder structure and ensure all folders exist in the mapping\n",
    "    for folder_name, folder_path in folders.items():\n",
    "        path = Path(folder_path)\n",
    "        relative_path = path.relative_to(root_path)\n",
    "        folder_structure[str(relative_path)] = {\"name\": folder_name, \"scripts\": []}\n",
    "\n",
    "    # Assign scripts to the correct folders\n",
    "    for script_name, script_path in scripts.items():\n",
    "        script_path_obj = Path(script_path)\n",
    "        parent_folder = script_path_obj.parent.relative_to(root_path)\n",
    "\n",
    "        # Ensure the parent folder exists in our dictionary before adding\n",
    "        parent_folder_str = str(parent_folder)\n",
    "        if parent_folder_str in folder_structure:\n",
    "            folder_structure[parent_folder_str][\"scripts\"].append(script_name)\n",
    "\n",
    "    # Generate the tree output\n",
    "    seen_folders = set()\n",
    "\n",
    "    def build_tree(path, depth=0):\n",
    "        \"\"\"Recursive function to format the tree output.\"\"\"\n",
    "        indent = \"│   \" * depth\n",
    "        path_str = str(path)\n",
    "\n",
    "        # Ensure we don't print duplicate folders\n",
    "        if path_str in seen_folders:\n",
    "            return\n",
    "        seen_folders.add(path_str)\n",
    "\n",
    "        tree.append(f\"{indent}├── {path.name}\")\n",
    "\n",
    "        # Add scripts belonging to this folder\n",
    "        if path_str in folder_structure:\n",
    "            for script in sorted(folder_structure[path_str][\"scripts\"]):\n",
    "                tree.append(f\"{indent}│   ├── {script}\")\n",
    "\n",
    "        # Recurse into subfolders\n",
    "        subfolders = [p for p in folder_structure if Path(p).parent == path]\n",
    "        for subfolder in sorted(subfolders):\n",
    "            build_tree(Path(subfolder), depth + 1)\n",
    "\n",
    "    # Build tree from the root folder\n",
    "    build_tree(Path(\".\"))  # \".\" represents the root of the model repo\n",
    "\n",
    "    # Add root-level files (only if they are not assigned elsewhere)\n",
    "    root_scripts = set(scripts.keys()) - {s for f in folder_structure.values() for s in f[\"scripts\"]}\n",
    "    root_files = [\"requirements.txt\", \"run.sh\"] + sorted(root_scripts)\n",
    "\n",
    "    for file in root_files:\n",
    "        tree.append(f\"├── {file}\")\n",
    "\n",
    "    return \"\\n\".join(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: chunky_cat\n",
      "Model: midnight_rain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory /home/sonja/Desktop/views-platform/views-models/models/midnight_rain/notebooks does not exist. Continuing...\n",
      "Directory /home/sonja/Desktop/views-platform/views-models/models/midnight_rain/notebooks does not exist. Continuing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: bad_blood\n",
      "Model: blank_space\n",
      "Model: high_hopes\n",
      "Model: counting_stars\n",
      "Model: demon_days\n",
      "Model: old_money\n",
      "Model: fast_car\n",
      "Model: popular_monster\n",
      "Model: green_squirrel\n",
      "Model: twin_flame\n",
      "Model: good_riddance\n",
      "Model: yellow_pikachu\n",
      "Model: wildest_dream\n",
      "Model: bittersweet_symphony\n",
      "Model: caring_fish\n",
      "Model: ominous_ox\n",
      "Model: little_lies\n",
      "Model: purple_alien\n",
      "Model: lavender_haze\n",
      "Model: teen_spirit\n",
      "Model: heavy_rotation\n",
      "Model: dark_paradise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory /home/sonja/Desktop/views-platform/views-models/models/dark_paradise/notebooks does not exist. Continuing...\n",
      "Directory /home/sonja/Desktop/views-platform/views-models/models/dark_paradise/notebooks does not exist. Continuing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: fluorescent_adolescent\n",
      "Model: orange_pasta\n",
      "Model: yellow_submarine\n",
      "Model: national_anthem\n",
      "Model: electric_relaxation\n",
      "Model: plastic_beach\n",
      "Model: brown_cheese\n",
      "Model: invisible_string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory /home/sonja/Desktop/views-platform/views-models/models/invisible_string/notebooks does not exist. Continuing...\n",
      "Directory /home/sonja/Desktop/views-platform/views-models/models/invisible_string/notebooks does not exist. Continuing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: car_radio\n"
     ]
    }
   ],
   "source": [
    "for subfolder in target_dir.iterdir():\n",
    "    if subfolder.is_dir():  # Check if it's a directory\n",
    "        print(f\"Model: {subfolder.name}\")\n",
    "        #configs_dir = Path(subfolder.name+\"/configs\")\n",
    "        configs_dir = target_dir / subfolder.name / \"configs\"\n",
    "        model_manager = ModelManager(model_path=ModelPathManager(configs_dir))\n",
    "        mpm = ModelPathManager(configs_dir)\n",
    "\n",
    "        ## Get Meta Info\n",
    "        model_name = model_manager.configs['name']\n",
    "        model_name = \" \".join(word.capitalize() for word in model_name.split(\"_\"))\n",
    "\n",
    "        algorithm = model_manager.configs['algorithm']\n",
    "        if algorithm=='HurdleModel':\n",
    "            classifier = model_manager.configs['model_clf']\n",
    "            regressor = model_manager.configs['model_reg']\n",
    "            algorithm_all = f\"{algorithm} (Classifier: {classifier}, Regressor: {regressor})\"\n",
    "        else:\n",
    "            algorithm_all = algorithm\n",
    "\n",
    "        target = model_manager.configs['depvar']\n",
    "        if isinstance(target, list):\n",
    "            target = \", \".join(target)\n",
    "        queryset = model_manager.configs['queryset']\n",
    "        level = model_manager.configs['level']\n",
    "        try:\n",
    "            metrics = model_manager.configs['metrics']\n",
    "        except KeyError:\n",
    "            metrics = \"No information provided\"\n",
    "        if isinstance(metrics, list):\n",
    "            metrics = \", \".join(metrics)\n",
    "\n",
    "        ## Get deployment mode \n",
    "        deployment = model_manager.configs['deployment_status']\n",
    "\n",
    "        ## Get queryset description\n",
    "        queryset_info = mpm.get_queryset()\n",
    "        description = queryset_info.description\n",
    "        try:\n",
    "            description = \" \".join(description.split())\n",
    "        except AttributeError:\n",
    "            description = 'No description provided'\n",
    "        name = queryset_info.name\n",
    "\n",
    "        ## Update old README file - For Bitter Symphony Model \n",
    "        scaffold_path = target_dir / \"README_scaffold.md\"\n",
    "        readme_path = target_dir / subfolder.name / \"README.md\"\n",
    "\n",
    "        # Read old README\n",
    "        with open(readme_path, \"r\") as file:\n",
    "            old_readme_content = file.read()\n",
    "\n",
    "        # Add created sessioin if it exists\n",
    "\n",
    "        match = re.search(r\"(## Created on.*)\", old_readme_content, re.DOTALL)\n",
    "        if match==None:\n",
    "            new_string=''\n",
    "        else:\n",
    "            created_section = match.group(1).strip()\n",
    "            insert_position = created_section.find(\"##\")\n",
    "\n",
    "            # Find where the '##' ends (after '##' and the next space)\n",
    "            end_of_heading = len(\"##\")  # Skip the '##' part itself\n",
    "            new_string = created_section[:end_of_heading] + \" \" + 'Model' + created_section[end_of_heading:]\n",
    "\n",
    "        # Read scaffold.md content\n",
    "        with open(scaffold_path, \"r\") as file:\n",
    "            content = file.read()\n",
    "\n",
    "\n",
    "        # Dictionary of placeholders and their replacements\n",
    "        replacements = {\n",
    "            \"{{MODEL_NAME}}\": model_name,\n",
    "            \"{{MODEL_ALGORITHM}}\": algorithm_all,\n",
    "            \"{{LEVEL_OF_ANALYSIS}}\": level,\n",
    "            \"{{TARGET}}\": target,\n",
    "            \"{{FEATURES}}\": name, \n",
    "            \"{{DESCRIPTION}}\": description,\n",
    "            \"{{DEPLOYMENT}}\": deployment,\n",
    "            \"{{METRICS}}\": metrics,\n",
    "            \"{{CREATED_SECTION}}\": new_string,\n",
    "        }\n",
    "\n",
    "\n",
    "        # Replace placeholders in scaffold content\n",
    "        for placeholder, value in replacements.items():\n",
    "            content = content.replace(placeholder, value)\n",
    "\n",
    "\n",
    "        repo_root = target_dir / subfolder.name\n",
    "        repo_structure = generate_repo_structure(mpm.get_directories(), mpm.get_scripts(), model_name=model_name)\n",
    "        formatted_structure = f\"```\\n{repo_structure}\\n```\"\n",
    "        formatted_structure\n",
    "\n",
    "\n",
    "        updated_readme = content.replace(\"## Repository Structure\",\n",
    "                f\"## Repository Structure\\n\\n{formatted_structure}\",\n",
    "            )\n",
    "        \n",
    "        # Write the updated content to README.md\n",
    "        with open(readme_path, \"w\") as file:\n",
    "            file.write(updated_readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Ensamble Models ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_manager = EnsembleManager(ensemble_path=EnsemblePathManager('/home/sonja/Desktop/views-platform/views-models/ensembles/cruel_summer'))\n",
    "#ens_manager.configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sonja/Desktop/views-platform/views-models/ensembles')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = os.getcwd()\n",
    "target_ens_dir = Path(base_dir+\"/ensembles/\")\n",
    "target_ens_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: cruel_summer\n",
      "Model: pink_ponyclub\n",
      "Model: white_mustang\n",
      "Model: skinny_love\n"
     ]
    }
   ],
   "source": [
    "for subfolder in target_ens_dir.iterdir():\n",
    "    if subfolder.is_dir():  # Check if it's a directory\n",
    "        print(f\"Model: {subfolder.name}\")\n",
    "        #configs_dir = Path(subfolder.name+\"/configs\")\n",
    "        configs_dir = target_ens_dir / subfolder.name / \"configs\"\n",
    "        ens_manager = EnsembleManager(ensemble_path=EnsemblePathManager(configs_dir))\n",
    "        epm = EnsemblePathManager(configs_dir)\n",
    "\n",
    "        ## Get Meta Info\n",
    "        ens_name = ens_manager.configs['name']\n",
    "        ens_name = \" \".join(word.capitalize() for word in ens_name.split(\"_\"))\n",
    "\n",
    "        models = ens_manager.configs['models']\n",
    "        models = \", \".join(models)\n",
    "\n",
    "        target = ens_manager.configs['depvar']\n",
    "        if isinstance(target, list):\n",
    "            target = \", \".join(target)\n",
    "        level = ens_manager.configs['level']\n",
    "        try:\n",
    "            metrics = ens_manager.configs['metrics']\n",
    "        except KeyError:\n",
    "            metrics = \"No information provided\"\n",
    "        if isinstance(metrics, list):\n",
    "            metrics = \", \".join(metrics)\n",
    "        \n",
    "        aggregation = ens_manager.configs['aggregation']\n",
    "\n",
    "        ## Get deployment mode \n",
    "        deployment = ens_manager.configs['deployment_status']\n",
    "\n",
    "        ## Update old README file - For Bitter Symphony Model \n",
    "        scaffold_path = target_ens_dir / \"README_ensemble_scaffold.md\"\n",
    "        readme_path = target_ens_dir / subfolder.name / \"README.md\"\n",
    "\n",
    "        # Read old README\n",
    "        with open(readme_path, \"r\") as file:\n",
    "            old_readme_content = file.read()\n",
    "\n",
    "        # Add created sessioin if it exists\n",
    "\n",
    "        match = re.search(r\"(## Created on.*)\", old_readme_content, re.DOTALL)\n",
    "        if match==None:\n",
    "            new_string=''\n",
    "        else:\n",
    "            created_section = match.group(1).strip()\n",
    "            insert_position = created_section.find(\"##\")\n",
    "\n",
    "            # Find where the '##' ends (after '##' and the next space)\n",
    "            end_of_heading = len(\"##\")  # Skip the '##' part itself\n",
    "            new_string = created_section[:end_of_heading] + \" \" + 'Model' + created_section[end_of_heading:]\n",
    "\n",
    "        # Read scaffold.md content\n",
    "        with open(scaffold_path, \"r\") as file:\n",
    "            content = file.read()\n",
    "\n",
    "\n",
    "        # Dictionary of placeholders and their replacements\n",
    "        replacements = {\n",
    "            \"{{ENSEMBLE_NAME}}\": ens_name,\n",
    "            \"{{MODELS}}\": models,\n",
    "            \"{{LEVEL_OF_ANALYSIS}}\": level,\n",
    "            \"{{TARGET}}\": target,\n",
    "            \"{{AGGREGATION}}\": aggregation,\n",
    "            \"{{DEPLOYMENT}}\": deployment,\n",
    "            \"{{METRICS}}\": metrics,\n",
    "            \"{{CREATED_SECTION}}\": new_string,\n",
    "        }\n",
    "\n",
    "\n",
    "        # Replace placeholders in scaffold content\n",
    "        for placeholder, value in replacements.items():\n",
    "            content = content.replace(placeholder, value)\n",
    "\n",
    "        repo_structure = generate_repo_structure(epm.get_directories(), epm.get_scripts(), model_name=ens_name)\n",
    "        formatted_structure = f\"```\\n{repo_structure}\\n```\"\n",
    "        formatted_structure\n",
    "\n",
    "\n",
    "        updated_readme = content.replace(\"## Repository Structure\",\n",
    "                f\"## Repository Structure\\n\\n{formatted_structure}\",\n",
    "            )\n",
    "        \n",
    "\n",
    "        # Write the updated content to README.md\n",
    "        with open(readme_path, \"w\") as file:\n",
    "            file.write(updated_readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'steps': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36],\n",
       " 'parameters': {'clf': {'n_estimators': 200}, 'reg': {'n_estimators': 200}},\n",
       " 'name': 'old_money',\n",
       " 'algorithm': 'HurdleModel',\n",
       " 'model_clf': 'LGBMClassifier',\n",
       " 'model_reg': 'LGBMRegressor',\n",
       " 'metrics': ['RMSLE', 'CRPS'],\n",
       " 'depvar': 'ln_ged_sb_dep',\n",
       " 'queryset': 'fatalities003_pgm_escwa_drought',\n",
       " 'level': 'pgm',\n",
       " 'creator': 'Xiaolong',\n",
       " 'deployment_status': 'shadow'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_manager.configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpm = ModelPathManager(\"/home/sonja/Desktop/views-platform/views-models/models/bad_blood/logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_dir': '/home/sonja/Desktop/views-platform/views-models/models/old_money',\n",
       " 'logging': '/home/sonja/Desktop/views-platform/views-models/models/old_money/logs',\n",
       " 'artifacts': '/home/sonja/Desktop/views-platform/views-models/models/old_money/artifacts',\n",
       " 'configs': '/home/sonja/Desktop/views-platform/views-models/models/old_money/configs',\n",
       " 'data': '/home/sonja/Desktop/views-platform/views-models/models/old_money/data',\n",
       " 'data_generated': '/home/sonja/Desktop/views-platform/views-models/models/old_money/data/generated',\n",
       " 'data_processed': '/home/sonja/Desktop/views-platform/views-models/models/old_money/data/processed',\n",
       " 'reports': '/home/sonja/Desktop/views-platform/views-models/models/old_money/reports',\n",
       " 'data_raw': '/home/sonja/Desktop/views-platform/views-models/models/old_money/data/raw',\n",
       " 'notebooks': '/home/sonja/Desktop/views-platform/views-models/models/old_money/notebooks'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpm.get_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dir (/home/sonja/Desktop/views-platform/views-models/models/old_money)\n",
      "\n",
      "├── artifacts\n",
      "├── configs\n",
      "├── data\n",
      "│   ├── generated\n",
      "│   ├── processed\n",
      "│   ├── raw\n",
      "├── logs\n",
      "├── notebooks\n",
      "├── reports\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def generate_repo_structure(folders, root_key=\"model_dir\"):\n",
    "    \"\"\"Generate a tree-like repository structure, starting from the model directory.\"\"\"\n",
    "    \n",
    "    # Ensure the root directory exists in the dictionary\n",
    "    if root_key not in folders:\n",
    "        raise ValueError(f\"Root key '{root_key}' not found in folders dictionary\")\n",
    "    \n",
    "    root_path = Path(folders[root_key])  # Get the main model directory path\n",
    "    sorted_items = sorted(folders.items(), key=lambda x: x[1])  # Sort paths\n",
    "    tree = []\n",
    "    seen_paths = set()\n",
    "\n",
    "    for folder, path in sorted_items:\n",
    "        path_obj = Path(path)\n",
    "        \n",
    "        # Skip folders that are not within the root directory\n",
    "        if root_path not in path_obj.parents and root_path != path_obj:\n",
    "            continue\n",
    "\n",
    "        # Convert path relative to root_path\n",
    "        relative_path = path_obj.relative_to(root_path)\n",
    "        path_parts = relative_path.parts  # Break it down into subfolder components\n",
    "        \n",
    "        # Construct each level of the hierarchy\n",
    "        structure = \"\"\n",
    "        for i, part in enumerate(path_parts):\n",
    "            indent = \"│   \" * i  # Indentation for hierarchy\n",
    "            if part not in seen_paths:\n",
    "                structure += f\"{indent}├── {part}\\n\"\n",
    "                seen_paths.add(part)\n",
    "\n",
    "        tree.append(structure.strip())\n",
    "\n",
    "    # Add the root directory at the top\n",
    "    return f\"{root_key} ({root_path})\\n\" + \"\\n\".join(tree)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "repo_structure = generate_repo_structure(mpm.get_directories())\n",
    "print(repo_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Money\n",
      "\n",
      "├── artifacts\n",
      "├── configs\n",
      "├── data\n",
      "│   ├── generated\n",
      "│   ├── processed\n",
      "│   ├── raw\n",
      "├── logs\n",
      "├── notebooks\n",
      "├── reports\n"
     ]
    }
   ],
   "source": [
    "def generate_repo_structure(folders, model_name, root_key=\"model_dir\"):\n",
    "    \"\"\"Generate a tree-like repository structure, starting from the model directory and showing model name.\"\"\"\n",
    "    \n",
    "    # Ensure the root directory exists in the dictionary\n",
    "    if root_key not in folders:\n",
    "        raise ValueError(f\"Root key '{root_key}' not found in folders dictionary\")\n",
    "    \n",
    "    root_path = Path(folders[root_key])  # Get the main model directory path\n",
    "    sorted_items = sorted(folders.items(), key=lambda x: x[1])  # Sort paths\n",
    "    tree = []\n",
    "    seen_paths = set()\n",
    "\n",
    "    for folder, path in sorted_items:\n",
    "        path_obj = Path(path)\n",
    "        \n",
    "        # Skip folders that are not within the root directory\n",
    "        if root_path not in path_obj.parents and root_path != path_obj:\n",
    "            continue\n",
    "\n",
    "        # Convert path relative to root_path\n",
    "        relative_path = path_obj.relative_to(root_path)\n",
    "        path_parts = relative_path.parts  # Break it down into subfolder components\n",
    "        \n",
    "        # Construct each level of the hierarchy\n",
    "        structure = \"\"\n",
    "        for i, part in enumerate(path_parts):\n",
    "            indent = \"│   \" * i  # Indentation for hierarchy\n",
    "            if part not in seen_paths:\n",
    "                structure += f\"{indent}├── {part}\\n\"\n",
    "                seen_paths.add(part)\n",
    "\n",
    "        tree.append(structure.strip())\n",
    "\n",
    "    # Add the model name at the top\n",
    "    return f\"{model_name}\\n\" + \"\\n\".join(tree)\n",
    "\n",
    "\n",
    "repo_structure = generate_repo_structure(mpm.get_directories(), model_name=model_name)\n",
    "print(repo_structure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_deployment.py': '/home/sonja/Desktop/views-platform/views-models/models/old_money/configs/config_deployment.py',\n",
       " 'config_hyperparameters.py': '/home/sonja/Desktop/views-platform/views-models/models/old_money/configs/config_hyperparameters.py',\n",
       " 'config_meta.py': '/home/sonja/Desktop/views-platform/views-models/models/old_money/configs/config_meta.py',\n",
       " 'main.py': '/home/sonja/Desktop/views-platform/views-models/models/old_money/main.py',\n",
       " 'README.md': '/home/sonja/Desktop/views-platform/views-models/models/old_money/README.md',\n",
       " 'config_queryset.py': '/home/sonja/Desktop/views-platform/views-models/models/old_money/configs/config_queryset.py',\n",
       " 'config_sweep.py': '/home/sonja/Desktop/views-platform/views-models/models/old_money/configs/config_sweep.py'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpm.get_scripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Money\n",
      "├── \n",
      "│   ├── README.md\n",
      "│   ├── main.py\n",
      "│   ├── artifacts\n",
      "│   ├── configs\n",
      "│   │   ├── config_deployment.py\n",
      "│   │   ├── config_hyperparameters.py\n",
      "│   │   ├── config_meta.py\n",
      "│   │   ├── config_queryset.py\n",
      "│   │   ├── config_sweep.py\n",
      "│   ├── data\n",
      "│   │   ├── generated\n",
      "│   │   ├── processed\n",
      "│   │   ├── raw\n",
      "│   ├── logs\n",
      "│   ├── notebooks\n",
      "│   ├── reports\n",
      "├── requirements.txt\n",
      "├── run.sh\n"
     ]
    }
   ],
   "source": [
    "def generate_repo_structure(folders, scripts, model_name, root_key=\"model_dir\"):\n",
    "    \"\"\"Generate a structured repository tree with correct folder hierarchy and script placement.\"\"\"\n",
    "\n",
    "    if root_key not in folders:\n",
    "        raise ValueError(f\"Root key '{root_key}' not found in folders dictionary\")\n",
    "\n",
    "    root_path = Path(folders[root_key])  # Get the main model directory path\n",
    "    tree = [model_name]  # Start with the model name\n",
    "    folder_structure = {}\n",
    "\n",
    "    # Build folder structure and ensure all folders exist in the mapping\n",
    "    for folder_name, folder_path in folders.items():\n",
    "        path = Path(folder_path)\n",
    "        relative_path = path.relative_to(root_path)\n",
    "        folder_structure[str(relative_path)] = {\"name\": folder_name, \"scripts\": []}\n",
    "\n",
    "    # Assign scripts to the correct folders\n",
    "    for script_name, script_path in scripts.items():\n",
    "        script_path_obj = Path(script_path)\n",
    "        parent_folder = script_path_obj.parent.relative_to(root_path)\n",
    "\n",
    "        # Ensure the parent folder exists in our dictionary before adding\n",
    "        parent_folder_str = str(parent_folder)\n",
    "        if parent_folder_str in folder_structure:\n",
    "            folder_structure[parent_folder_str][\"scripts\"].append(script_name)\n",
    "\n",
    "    # Generate the tree output\n",
    "    seen_folders = set()\n",
    "\n",
    "    def build_tree(path, depth=0):\n",
    "        \"\"\"Recursive function to format the tree output.\"\"\"\n",
    "        indent = \"│   \" * depth\n",
    "        path_str = str(path)\n",
    "\n",
    "        # Ensure we don't print duplicate folders\n",
    "        if path_str in seen_folders:\n",
    "            return\n",
    "        seen_folders.add(path_str)\n",
    "\n",
    "        tree.append(f\"{indent}├── {path.name}\")\n",
    "\n",
    "        # Add scripts belonging to this folder\n",
    "        if path_str in folder_structure:\n",
    "            for script in sorted(folder_structure[path_str][\"scripts\"]):\n",
    "                tree.append(f\"{indent}│   ├── {script}\")\n",
    "\n",
    "        # Recurse into subfolders\n",
    "        subfolders = [p for p in folder_structure if Path(p).parent == path]\n",
    "        for subfolder in sorted(subfolders):\n",
    "            build_tree(Path(subfolder), depth + 1)\n",
    "\n",
    "    # Build tree from the root folder\n",
    "    build_tree(Path(\".\"))  # \".\" represents the root of the model repo\n",
    "\n",
    "    # Add root-level files (only if they are not assigned elsewhere)\n",
    "    root_scripts = set(scripts.keys()) - {s for f in folder_structure.values() for s in f[\"scripts\"]}\n",
    "    root_files = [\"requirements.txt\", \"run.sh\"] + sorted(root_scripts)\n",
    "\n",
    "    for file in root_files:\n",
    "        tree.append(f\"├── {file}\")\n",
    "\n",
    "    return \"\\n\".join(tree)\n",
    "repo_structure = generate_repo_structure(mpm.get_directories(), mpm.get_scripts(), model_name=model_name)\n",
    "print(repo_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name                \tPath                                              \n",
      "========================================================================\n",
      "root                \t/home/sonja/Desktop/views-platform/views-models   \n",
      "logging             \t/home/sonja/Desktop/views-platform/views-models/models/old_money/logs\n",
      "artifacts           \t/home/sonja/Desktop/views-platform/views-models/models/old_money/artifacts\n",
      "configs             \t/home/sonja/Desktop/views-platform/views-models/models/old_money/configs\n",
      "data                \t/home/sonja/Desktop/views-platform/views-models/models/old_money/data\n",
      "data_generated      \t/home/sonja/Desktop/views-platform/views-models/models/old_money/data/generated\n",
      "data_processed      \t/home/sonja/Desktop/views-platform/views-models/models/old_money/data/processed\n",
      "reports             \t/home/sonja/Desktop/views-platform/views-models/models/old_money/reports\n",
      "data_raw            \t/home/sonja/Desktop/views-platform/views-models/models/old_money/data/raw\n",
      "notebooks           \t/home/sonja/Desktop/views-platform/views-models/models/old_money/notebooks\n"
     ]
    }
   ],
   "source": [
    "mpm.view_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretend = ModelPathManager(\"orange_cat\", validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_dir': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat',\n",
       " 'logging': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/logs',\n",
       " 'artifacts': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/artifacts',\n",
       " 'configs': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/configs',\n",
       " 'data': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/data',\n",
       " 'data_generated': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/data/generated',\n",
       " 'data_processed': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/data/processed',\n",
       " 'reports': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/reports',\n",
       " 'data_raw': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/data/raw',\n",
       " 'notebooks': '/home/sonja/Desktop/views-platform/views-models/models/orange_cat/notebooks'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretend.get_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sonja/Desktop/views-platform/views-models/models')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpm.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sonja/Desktop/views-platform/views-models')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpm.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No model artifacts found for run type 'forecasting' in path '/home/sonja/Desktop/views-platform/views-models/models/bad_blood/artifacts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmpm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_latest_model_artifact_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforecasting\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/views-platform/views-pipeline-core/views_pipeline_core/managers/model.py:428\u001b[39m, in \u001b[36mModelPathManager.get_latest_model_artifact_path\u001b[39m\u001b[34m(self, run_type)\u001b[39m\n\u001b[32m    425\u001b[39m model_files = \u001b[38;5;28mself\u001b[39m._get_artifact_files(run_type=run_type)\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_files:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m    429\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo model artifacts found for run type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m in path \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.artifacts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    430\u001b[39m     )\n\u001b[32m    432\u001b[39m \u001b[38;5;66;03m# Sort the files based on the timestamp embedded in the filename. With format %Y%m%d_%H%M%S For example, '20210831_123456.pt'\u001b[39;00m\n\u001b[32m    433\u001b[39m model_files.sort(reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No model artifacts found for run type 'forecasting' in path '/home/sonja/Desktop/views-platform/views-models/models/bad_blood/artifacts'"
     ]
    }
   ],
   "source": [
    "mpm.get_latest_model_artifact_path(run_type=\"forecasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Queryset(name='fatalities003_pgm_natsoc', loa='priogrid_month', themes=['fatalities'], description='Fatalities natural and social geography, pgm level\\n\\n                                    Predicting ln(fatalities) using natural and social geography features\\n\\n                                    ', operations=[[RenameOperation(namespace='trf', name='util.rename', arguments=['ln_ged_sb_dep']), TransformOperation(namespace='trf', name='ops.ln', arguments=[]), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_month.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['ln_ged_sb']), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='ops.ln', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_month.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['imr_mean']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.imr_mean', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['mountains_mean']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.mountains_mean', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['dist_diamsec']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid.dist_diamsec_s_wgs', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['dist_petroleum']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid.dist_petroleum_s_wgs', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['agri_ih']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.agri_ih', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['barren_ih']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.barren_ih', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['forest_ih']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.forest_ih', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['pasture_ih']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.pasture_ih', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['savanna_ih']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.savanna_ih', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['shrub_ih']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.shrub_ih', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['urban_ih']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.urban_ih', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['ln_pop_gpw_sum']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='ops.ln', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.pop_gpw_sum', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['ln_ttime_mean']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='ops.ln', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.ttime_mean', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['ln_gcp_mer']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='ops.ln', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.gcp_mer', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['ln_bdist3']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='ops.ln', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.bdist3', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['ln_capdist']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='ops.ln', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_year.capdist', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['greq_1_excluded']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='missing.fill', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['1']), DatabaseOperation(namespace='base', name='priogrid_year.excluded', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['decay_ged_sb_1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='temporal.decay', arguments=['24']), TransformOperation(namespace='trf', name='temporal.time_since', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_month.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['decay_ged_sb_25']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='temporal.decay', arguments=['24']), TransformOperation(namespace='trf', name='temporal.time_since', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['25']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_month.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['decay_ged_os_1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='temporal.decay', arguments=['24']), TransformOperation(namespace='trf', name='temporal.time_since', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_month.ged_os_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_1_1_sb_1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.lag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='temporal.decay', arguments=['24']), TransformOperation(namespace='trf', name='temporal.time_since', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_month.ged_sb_best_sum_nokgi', arguments=['values'])], [RenameOperation(namespace='trf', name='util.rename', arguments=['splag_1_decay_ged_sb_1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), TransformOperation(namespace='trf', name='spatial.lag', arguments=['1', '1', '0', '0']), TransformOperation(namespace='trf', name='temporal.decay', arguments=['24']), TransformOperation(namespace='trf', name='temporal.time_since', arguments=[]), TransformOperation(namespace='trf', name='bool.gte', arguments=['1']), TransformOperation(namespace='trf', name='missing.replace_na', arguments=[]), DatabaseOperation(namespace='base', name='priogrid_month.ged_sb_best_sum_nokgi', arguments=['values'])]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpm.get_queryset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
