{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Original Grid Forecasts: [ 0.  0.  0.  0.  0.  5.  0.  0.  0.  0.  0. 58.  0.  0.  0. 86.  0.  0.\n",
      "  0.  0. 82.  0.  0.  0.  0. 63. 45.  0.  0. 28.  0.  0.  0. 75.  0. 50.\n",
      " 13.  0.  0.  0. 39.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0. 54.  4. 53.  0. 64. 55.  0.  0.  0. 82.  0.  0. 98.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. 43.  0.  0. 14.  0.  0.  0. 33. 97.  0. 66. 68.\n",
      " 75.  0.  0.  0.  0.  0.  0.  9.  0.  0.]\n",
      "\n",
      "ðŸ”¹ Adjusted Grid Forecasts: [  0   0   0   0   0   6   0   0   0   0   0  70   0   0   0 103   0   0\n",
      "   0   0  98   0   0   0   0  76  54   0   0  34   0   0   0  90   0  60\n",
      "  16   0   0   0  46   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  64   5  64   0  76  66   0   0   0  98   0   0 118   0   0\n",
      "   0   0   0   0   0   0  52   0   0  17   0   0   0  40 116   0  79  82\n",
      "  90   0   0   0   0   0   0  11   0   0]\n",
      "\n",
      "ðŸ”¹ Sum of Adjusted Forecasts: 1631\n",
      "\n",
      "ðŸ”¹ Country Forecast: 1630.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def reconcile_forecast_torch(grid_forecast: torch.Tensor, country_forecast: float, lr=0.01, max_iters=1000, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Adjusts grid-level forecasts in PyTorch while preserving zero values and ensuring\n",
    "    the sum matches the country-level forecast. Final output is rounded to integers with high precision.\n",
    "    \n",
    "    Parameters:\n",
    "        grid_forecast (torch.Tensor): Original grid-level forecasts (non-negative).\n",
    "        country_forecast (float): The total forecast for the country.\n",
    "        lr (float): Learning rate for optimization.\n",
    "        max_iters (int): Maximum iterations for gradient descent.\n",
    "        tol (float): Convergence tolerance for precise adjustment.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Adjusted grid forecasts (integer counts) summing to country_forecast.\n",
    "    \"\"\"\n",
    "    # Ensure input tensor is float and non-negative\n",
    "    grid_forecast = grid_forecast.clone().float()\n",
    "    assert torch.all(grid_forecast >= 0), \"Grid forecasts must be non-negative\"\n",
    "    assert country_forecast >= 0, \"Country forecast must be non-negative\"\n",
    "\n",
    "    # Identify nonzero elements\n",
    "    mask_nonzero = grid_forecast > 0\n",
    "    nonzero_values = grid_forecast[mask_nonzero]\n",
    "\n",
    "    # If all values are zero, return unchanged\n",
    "    if len(nonzero_values) == 0:\n",
    "        return grid_forecast\n",
    "\n",
    "    # Initial guess: proportional scaling for nonzero values\n",
    "    adjusted_values = nonzero_values * (country_forecast / max(nonzero_values.sum(), 1e-8))\n",
    "    adjusted_values = adjusted_values.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # Use LBFGS optimizer for more precise optimization\n",
    "    optimizer = torch.optim.LBFGS([adjusted_values], lr=lr, max_iter=max_iters, tolerance_grad=tol)\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.sum((adjusted_values - nonzero_values) ** 2)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    # Projection Step: Ensure sum constraint and non-negativity\n",
    "    with torch.no_grad():\n",
    "        scaling_factor = country_forecast / max(adjusted_values.sum(), 1e-8)\n",
    "        adjusted_values *= scaling_factor  # Scale to match country total\n",
    "        adjusted_values.clamp_(min=0)  # Ensure non-negativity\n",
    "\n",
    "    # **Step 2: Round values with precise sum adjustment**\n",
    "    with torch.no_grad():\n",
    "        rounded_values = adjusted_values.round()  # Round to nearest integer\n",
    "\n",
    "        # Compute rounding error\n",
    "        rounding_error = int(country_forecast - rounded_values.sum())\n",
    "\n",
    "        if rounding_error != 0:\n",
    "            # Compute fractional parts\n",
    "            fractional_parts = adjusted_values - adjusted_values.floor()\n",
    "\n",
    "            # Sort indices by largest fractional part to minimize distortion\n",
    "            sorted_indices = torch.argsort(fractional_parts, descending=True)\n",
    "\n",
    "            # Redistribute rounding error\n",
    "            for i in range(abs(rounding_error)):\n",
    "                idx = sorted_indices[i % len(sorted_indices)]\n",
    "                if rounding_error > 0:\n",
    "                    rounded_values[idx] += 1  # Add 1 to highest fractional value\n",
    "                else:\n",
    "                    rounded_values[idx] -= 1  # Subtract 1 from lowest fractional value\n",
    "\n",
    "    # Create final adjusted forecast (preserve zero values)\n",
    "    adjusted_forecast = grid_forecast.clone()\n",
    "    adjusted_forecast[mask_nonzero] = rounded_values.detach()\n",
    "\n",
    "    return adjusted_forecast.long()  # Convert to integer tensor\n",
    "\n",
    "# âœ… **Test with a Large Zero-Inflated Right-Skewed Distribution**\n",
    "#torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Generate a highly zero-inflated dataset\n",
    "num_grid_cells = 100  # Large number of grid cells\n",
    "zero_mask = torch.rand(num_grid_cells) < 0.7  # 70% zeros\n",
    "grid_forecast_torch = torch.randint(1, 100, (num_grid_cells,), dtype=torch.float32)  # Right-skewed\n",
    "grid_forecast_torch[zero_mask] = 0  # Apply zero-inflation\n",
    "\n",
    "country_forecast_torch = grid_forecast_torch.sum().item() * 1.2  # 20% over-forecast at the country level\n",
    "\n",
    "# Run reconciliation\n",
    "adjusted_grid_forecast_torch = reconcile_forecast_torch(grid_forecast_torch, country_forecast_torch)\n",
    "\n",
    "# âœ… **Results**\n",
    "print(\"\\nðŸ”¹ Original Grid Forecasts:\", grid_forecast_torch.numpy())\n",
    "print(\"\\nðŸ”¹ Adjusted Grid Forecasts:\", adjusted_grid_forecast_torch.numpy())\n",
    "print(\"\\nðŸ”¹ Sum of Adjusted Forecasts:\", adjusted_grid_forecast_torch.sum().item())  # Should match country_forecast\n",
    "print(\"\\nðŸ”¹ Country Forecast:\", country_forecast_torch)  # Should match sum of adjusted forecasts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Running Tests on Forecast Reconciliation...\n",
      "\n",
      "ðŸ”¹ Standard case (1000 samples, 100 grid cells)\n",
      "   âœ… Completed in 0.445 sec\n",
      "   ðŸ” Max Sum Difference: 0.000366\n",
      "   ðŸ” Zeros Correctly Preserved: True\n",
      "\n",
      "ðŸ”¹ All zeros (should remain zero)\n",
      "   âœ… Completed in 0.002 sec\n",
      "   ðŸ” Max Sum Difference: 0.000000\n",
      "   ðŸ” Zeros Correctly Preserved: True\n",
      "\n",
      "ðŸ”¹ Extreme skew (heavy right tail)\n",
      "   âœ… Completed in 0.003 sec\n",
      "   ðŸ” Max Sum Difference: 0.000000\n",
      "   ðŸ” Zeros Correctly Preserved: True\n",
      "\n",
      "ðŸ”¹ Large scale (10,000 samples, 500 grid cells)\n",
      "   âœ… Completed in 0.010 sec\n",
      "   ðŸ” Max Sum Difference: 0.002930\n",
      "   ðŸ” Zeros Correctly Preserved: True\n",
      "\n",
      "\n",
      "âœ… All Tests Passed Successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def reconcile_forecast_samples_torch(grid_forecast_samples: torch.Tensor, country_forecast_samples: torch.Tensor, \n",
    "                                     lr=0.01, max_iters=500, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Adjusts each posterior sample of grid-level forecasts to ensure sum consistency with the \n",
    "    corresponding country-level forecast, using per-sample quadratic optimization.\n",
    "    \n",
    "    Parameters:\n",
    "        grid_forecast_samples (torch.Tensor): Tensor of shape (num_samples, num_grid_cells) \n",
    "                                              containing posterior samples for grid forecasts.\n",
    "        country_forecast_samples (torch.Tensor): Tensor of shape (num_samples,) containing \n",
    "                                                 posterior samples for the country-level forecast.\n",
    "        lr (float): Learning rate for optimization.\n",
    "        max_iters (int): Maximum iterations for gradient descent.\n",
    "        tol (float): Convergence tolerance for precise adjustment.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Adjusted grid forecasts with sum-matching for each posterior sample.\n",
    "    \"\"\"\n",
    "    # Ensure input is float and non-negative\n",
    "    grid_forecast_samples = grid_forecast_samples.clone().float()\n",
    "    country_forecast_samples = country_forecast_samples.clone().float()\n",
    "    \n",
    "    assert torch.all(grid_forecast_samples >= 0), \"Grid forecasts must be non-negative\"\n",
    "    assert torch.all(country_forecast_samples >= 0), \"Country forecasts must be non-negative\"\n",
    "    assert grid_forecast_samples.shape[0] == country_forecast_samples.shape[0], \"Mismatch in sample count\"\n",
    "\n",
    "    # Identify nonzero values for each sample (boolean mask)\n",
    "    mask_nonzero = grid_forecast_samples > 0  # Shape: (num_samples, num_grid_cells)\n",
    "\n",
    "    # Extract nonzero values only for optimization\n",
    "    nonzero_values = grid_forecast_samples.clone()\n",
    "    nonzero_values[~mask_nonzero] = 0  # Set zero values explicitly\n",
    "\n",
    "    # Initial proportional scaling for nonzero values\n",
    "    sum_nonzero = nonzero_values.sum(dim=1, keepdim=True)  # Sum per sample\n",
    "    scaling_factors = country_forecast_samples.view(-1, 1) / (sum_nonzero + 1e-8)\n",
    "    adjusted_values = nonzero_values * scaling_factors  # Proportional scaling\n",
    "    \n",
    "    # Ensure requires_grad for optimization\n",
    "    adjusted_values = adjusted_values.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # Optimizer: L-BFGS (better for constrained optimization)\n",
    "    optimizer = torch.optim.LBFGS([adjusted_values], lr=lr, max_iter=max_iters, tolerance_grad=tol)\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.sum((adjusted_values - nonzero_values) ** 2)  # Minimize distortion\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    # Projection Step: Ensure sum constraint and non-negativity\n",
    "    with torch.no_grad():\n",
    "        sum_adjusted = adjusted_values.sum(dim=1, keepdim=True)\n",
    "        scaling_factors = country_forecast_samples.view(-1, 1) / (sum_adjusted + 1e-8)\n",
    "        adjusted_values *= scaling_factors  # Scale to match country total\n",
    "        adjusted_values.clamp_(min=0)  # Ensure non-negativity\n",
    "\n",
    "    # Corrected Assignment: Use Masked Indexing Properly\n",
    "    final_adjusted = grid_forecast_samples.clone()\n",
    "    final_adjusted[mask_nonzero] = adjusted_values[mask_nonzero].detach()\n",
    "\n",
    "    return final_adjusted\n",
    "\n",
    "\n",
    "# âœ… **Comprehensive Testing**\n",
    "def run_tests():\n",
    "    torch.manual_seed(42)  # For reproducibility\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(\"\\nðŸ§ª Running Tests on Forecast Reconciliation...\\n\")\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Standard case (1000 samples, 100 grid cells)\",\n",
    "            \"num_samples\": 1000,\n",
    "            \"num_grid_cells\": 100,\n",
    "            \"zero_fraction\": 0.7,\n",
    "            \"scaling_factor\": 1.2\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"All zeros (should remain zero)\",\n",
    "            \"num_samples\": 1000,\n",
    "            \"num_grid_cells\": 100,\n",
    "            \"zero_fraction\": 1.0,  # All zeros\n",
    "            \"scaling_factor\": 1.2\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Extreme skew (heavy right tail)\",\n",
    "            \"num_samples\": 1000,\n",
    "            \"num_grid_cells\": 100,\n",
    "            \"zero_fraction\": 0.3,  # Some zeros\n",
    "            \"scaling_factor\": 10  # Extreme upscaling\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Large scale (10,000 samples, 500 grid cells)\",\n",
    "            \"num_samples\": 10000,\n",
    "            \"num_grid_cells\": 500,\n",
    "            \"zero_fraction\": 0.5,\n",
    "            \"scaling_factor\": 1.1\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for test in test_cases:\n",
    "        print(f\"ðŸ”¹ {test['name']}\")\n",
    "\n",
    "        num_samples = test[\"num_samples\"]\n",
    "        num_grid_cells = test[\"num_grid_cells\"]\n",
    "\n",
    "        zero_mask = torch.rand((num_samples, num_grid_cells)) < test[\"zero_fraction\"]\n",
    "        grid_forecast_samples = torch.randint(1, 100, (num_samples, num_grid_cells), dtype=torch.float32)\n",
    "        grid_forecast_samples[zero_mask] = 0  # Apply zero-inflation\n",
    "\n",
    "        country_forecast_samples = grid_forecast_samples.sum(dim=1) * test[\"scaling_factor\"]\n",
    "\n",
    "        # Move tensors to GPU if available\n",
    "        grid_forecast_samples = grid_forecast_samples.to(device)\n",
    "        country_forecast_samples = country_forecast_samples.to(device)\n",
    "\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Run reconciliation\n",
    "        adjusted_grid_forecast_samples = reconcile_forecast_samples_torch(grid_forecast_samples, country_forecast_samples)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"   âœ… Completed in {end_time - start_time:.3f} sec\")\n",
    "\n",
    "        # **Validation Checks**\n",
    "        sum_diff = torch.abs(adjusted_grid_forecast_samples.sum(dim=1) - country_forecast_samples).max().item()\n",
    "        assert sum_diff < 1e-2, \"âŒ Sum constraint violated!\"\n",
    "\n",
    "        zero_preservation = torch.all(grid_forecast_samples == 0) == torch.all(adjusted_grid_forecast_samples == 0)\n",
    "        assert zero_preservation, \"âŒ Zero-inflation not preserved!\"\n",
    "\n",
    "        print(f\"   ðŸ” Max Sum Difference: {sum_diff:.6f}\")\n",
    "        print(f\"   ðŸ” Zeros Correctly Preserved: {zero_preservation}\\n\")\n",
    "\n",
    "    print(\"\\nâœ… All Tests Passed Successfully!\")\n",
    "\n",
    "\n",
    "# Run tests\n",
    "run_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Running on: cuda\n",
      "\n",
      "ðŸ”„ Adjusting Posterior Samples...\n",
      "âœ… Adjustment Completed in 0.008 seconds!\n",
      "\n",
      "ðŸ” Sample Results:\n",
      "Original Grid Forecast Sum (First 5 Samples): [1886.  983. 1558. 1235.  967.]\n",
      "Adjusted Grid Forecast Sum (First 5 Samples): [2263.2002 1179.6001 1869.6001 1482.     1160.4   ]\n",
      "Country Forecasts (First 5 Samples): [2263.2002 1179.6001 1869.6001 1482.     1160.4   ]\n",
      "\n",
      "ðŸŽ¯ Final Checks:\n",
      "âœ… Max Sum Difference: 0.0003662109\n",
      "âœ… Zero Values Correctly Preserved: True\n",
      "\n",
      "ðŸŽ‰ Success! Posterior reconciliation is working perfectly!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# **Step 1: Set up device (CPU/GPU)**\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ðŸš€ Running on: {device}\")\n",
    "\n",
    "# **Step 2: Generate Posterior Forecast Samples**\n",
    "num_samples = 1000  # 1000 posterior draws\n",
    "num_grid_cells = 100  # 100 spatial grid cells\n",
    "\n",
    "torch.manual_seed(42)  # Ensure reproducibility\n",
    "\n",
    "# Generate zero-inflated forecast samples (70% zeros)\n",
    "zero_mask = torch.rand((num_samples, num_grid_cells)) < 0.7  \n",
    "grid_forecast_samples = torch.randint(1, 100, (num_samples, num_grid_cells), dtype=torch.float32)\n",
    "grid_forecast_samples[zero_mask] = 0  # Apply zero-inflation\n",
    "\n",
    "# Compute country-level forecasts (120% over-forecast)\n",
    "country_forecast_samples = grid_forecast_samples.sum(dim=1) * 1.2\n",
    "\n",
    "# Move data to GPU if available\n",
    "grid_forecast_samples = grid_forecast_samples.to(device)\n",
    "country_forecast_samples = country_forecast_samples.to(device)\n",
    "\n",
    "# **Step 3: Run Reconciliation**\n",
    "print(\"\\nðŸ”„ Adjusting Posterior Samples...\")\n",
    "start_time = time.time()\n",
    "\n",
    "adjusted_grid_forecast_samples = reconcile_forecast_samples_torch(grid_forecast_samples, country_forecast_samples)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"âœ… Adjustment Completed in {end_time - start_time:.3f} seconds!\")\n",
    "\n",
    "# **Step 4: Verify Results**\n",
    "print(\"\\nðŸ” Sample Results:\")\n",
    "print(\"Original Grid Forecast Sum (First 5 Samples):\", grid_forecast_samples.sum(dim=1)[:5].cpu().numpy())\n",
    "print(\"Adjusted Grid Forecast Sum (First 5 Samples):\", adjusted_grid_forecast_samples.sum(dim=1)[:5].cpu().numpy())\n",
    "print(\"Country Forecasts (First 5 Samples):\", country_forecast_samples[:5].cpu().numpy())\n",
    "\n",
    "# **Step 5: Validations**\n",
    "max_sum_diff = torch.abs(adjusted_grid_forecast_samples.sum(dim=1) - country_forecast_samples).max().item()\n",
    "assert max_sum_diff < 1e-2, \"âŒ Sum constraint violated!\"\n",
    "\n",
    "zero_preserved = torch.all(grid_forecast_samples == 0) == torch.all(adjusted_grid_forecast_samples == 0)\n",
    "assert zero_preserved, \"âŒ Zero-inflation not preserved!\"\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Final Checks:\")\n",
    "print(f\"âœ… Max Sum Difference: {max_sum_diff:.10f}\")\n",
    "print(f\"âœ… Zero Values Correctly Preserved: {zero_preserved}\")\n",
    "print(\"\\nðŸŽ‰ Success! Posterior reconciliation is working perfectly!\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "views_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
